{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segragate file\n",
    "- Blast only allow limited size\n",
    "- Thus seperate it to several files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "filename = \"LWW016_all.fas\"\n",
    "path = \"data\\\\fasta_file\\\\LWW016_all.fas\"\n",
    "\n",
    "def read_fas_as_list(path):\n",
    "    pattern = r\"[>][^>]+\"\n",
    "    with open (path,\"r\") as f:\n",
    "        whole_data = f.read()\n",
    "        return re.findall(pattern,whole_data)\n",
    "\n",
    "def part_folder (num = 50000):\n",
    "    datalist = read_fas_as_list(path)\n",
    "    count = len(datalist[0])\n",
    "    item_index = 0\n",
    "    folder_num = 1\n",
    "    temptxt = \"\"\n",
    "\n",
    "    while item_index < len(datalist):\n",
    "        count += len(datalist[item_index])\n",
    "        if count < num:\n",
    "            temptxt += datalist[item_index]\n",
    "            item_index += 1\n",
    "        else:\n",
    "            newpath = \"data\\\\fasta_file\\\\output\\\\\" + filename[:-4] + \"_\" + str(folder_num) + \".fas\"\n",
    "            with open (newpath, \"w\") as f:\n",
    "                f.write(temptxt)\n",
    "            folder_num += 1\n",
    "            count = len(datalist[item_index])\n",
    "            temptxt = datalist[item_index]\n",
    "            item_index += 1\n",
    "\n",
    "    newpath = \"data\\\\fasta_file\\\\output\\\\\" + filename[:-4] + \"_\" + str(folder_num) + \".fas\"\n",
    "    with open (newpath, \"w\") as f:\n",
    "                f.write(temptxt)\n",
    "\n",
    "part_folder ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blastn download as json\n",
    "- parse json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "file_name = \"data\\\\blast_result\\\\blastoutput.json\"\n",
    "\n",
    "query = []\n",
    "accesssion = []\n",
    "identity = []\n",
    "sciname = []\n",
    "title = []\n",
    "\n",
    "\n",
    "with open(file_name) as obj:\n",
    "    getDatas = json.load(obj)\n",
    "\n",
    "for getData in getDatas:\n",
    "    for item in getDatas[getData]:\n",
    "        query.append((item['report']['results']['search']['query_title']))\n",
    "        accesssion.append(item['report']['results']['search']['hits'][0]['description'][0]['accession'])\n",
    "        sciname.append(item['report']['results']['search']['hits'][0]['description'][0]['sciname'])\n",
    "        title.append(item['report']['results']['search']['hits'][0]['description'][0]['title'])\n",
    "        identity.append(item['report']['results']['search']['hits'][0][\"hsps\"][0]['identity']/10)\n",
    "\n",
    "\n",
    "df = pd.DataFrame([query, accesssion, identity, sciname, title]).transpose()\n",
    "df.columns = ['query', 'accesssion', 'identity', 'sciname', 'title']\n",
    "df.to_csv(\"data\\\\blast_result\\\\output\\\\output.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blastn\n",
    "\n",
    "from Bio.Blast import NCBIWWW\n",
    "\n",
    "path = \"data\\\\fasta_file\\\\output\\\\LWW016_all_1.fas\"\n",
    "outpath = \"data\\\\blast_result\\\\blast_output.xml\"\n",
    "\n",
    "def Blast_fasta(path,outpath):\n",
    "\n",
    "    with open (path) as obj:\n",
    "        fasta_file = obj.read()\n",
    "\n",
    "    blast_result = NCBIWWW.qblast(\"blastn\", \"nt\", fasta_file, megablast=True, hitlist_size=10)\n",
    "    out = blast_result.read()\n",
    "\n",
    "    with open(outpath, \"w\") as output_xml:\n",
    "        output_xml.write(out)\n",
    "\n",
    "    blast_result.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filelist = os.listdir(\"data\\\\fasta_file\\\\output\")\n",
    "for item in filelist:\n",
    "    path = \"data\\\\fasta_file\\\\output\\\\\" + item\n",
    "    outpath = \"data\\\\blast_result\\\\output\\\\\" + item[:-4]+ \"_out.xml\"\n",
    "    Blast_fasta(path,outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/138 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# filelist = os.listdir(\"data\\\\fasta_file\\\\output\")\n",
    "\n",
    "# def work(item):\n",
    "#     path = \"data\\\\fasta_file\\\\output\\\\\" + item\n",
    "#     outpath = \"data\\\\blast_result\\\\output\\\\\" + item[:-4]+ \"_out.xml\"\n",
    "#     Blast_fasta(path,outpath)\n",
    "\n",
    "# import tqdm\n",
    "# from multiprocessing import Pool\n",
    "# with Pool(1) as p:\n",
    "#     list(tqdm.tqdm(p.imap(work, filelist), total=len(filelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LWW016_all_86.fas Blastn success!\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#Blastn\n",
    "\n",
    "import re\n",
    "outfilelist = []\n",
    "outfile = os.listdir(\"data\\\\blast_result\\\\output\")\n",
    "pattern = r\"[_][0-9]+\"\n",
    "for item in outfile:\n",
    "    result = re.search(pattern,item)\n",
    "    if result:\n",
    "        outfilelist.append(item[result.start():result.end()])\n",
    "\n",
    "templist = []\n",
    "import os\n",
    "filelist = os.listdir(\"data\\\\fasta_file\\\\output\")\n",
    "filelist = sorted(filelist,reverse=True)\n",
    "for item in filelist:\n",
    "    result = (re.search(pattern,item))\n",
    "    temp = item[result.start():result.end()]\n",
    "    if temp in outfilelist:\n",
    "        pass\n",
    "    else:\n",
    "        path = \"data\\\\fasta_file\\\\output\\\\\" + item\n",
    "        outpath = \"data\\\\blast_result\\\\output\\\\\" + item[:-4]+ \"_out.xml\"\n",
    "        try:\n",
    "            Blast_fasta(path,outpath)\n",
    "            print(item + \" Blastn success!\")\n",
    "            print(\"-\"*10)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read xml information\n",
    "\n",
    "result_dict = {}\n",
    "temp_query = \"\"\n",
    "count = 0\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as  ET\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "filelist = os.listdir(\"data\\\\blast_result\\\\output\")\n",
    "filelist = sorted(filelist, reverse=True)\n",
    "\n",
    "for i in filelist:\n",
    "    path = \"data\\\\blast_result\\\\output\\\\\" + i\n",
    "    for event, item in ET.iterparse(path,events=(\"start\", \"end\")):\n",
    "        if item.tag == 'Iteration_query-def' and event == \"start\":\n",
    "            temp_query = item.text\n",
    "        if item.tag == 'Hit' and event == \"start\":\n",
    "            try:\n",
    "                if item[0].text == '1':\n",
    "                    count+=1\n",
    "                    try:\n",
    "                        pattern = \"[\\w]+ [\\w]+\"\n",
    "                        reres = re.search(pattern, item[2].text)\n",
    "                        result_dict[temp_query] = [item[2].text[reres.start():reres.end()].replace(\" \", \"_\")] #sci_name\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        result_dict[temp_query].append(item[3].text) #accession\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        result_dict[temp_query].append(f\"{(int(item[5][0][10].text)/int(item[5][0][13].text))*100}\") #identity\n",
    "\n",
    "                        \n",
    "                    except:\n",
    "                        pass\n",
    "            except:\n",
    "                # print(\"query \" + str(count) + \" error\")\n",
    "                count+=1\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read original all file and modify info\n",
    "path = \"data\\\\fasta_file\\\\LWW016_all.fas\"\n",
    "\n",
    "def read_all_file(path):\n",
    "    with open (path, \"r\") as obj:\n",
    "        txt = obj.read()\n",
    "    return txt    \n",
    "\n",
    "txt = read_all_file(path)\n",
    "abc=0\n",
    "import re\n",
    "\n",
    "for item in result_dict:\n",
    "    pattern = item\n",
    "    try:\n",
    "        txt = re.sub(pattern, result_dict[item][0] + \"_\" + result_dict[item][1] + \"_\" + result_dict[item][2] + \"_\" + item, txt)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write output to fasta\n",
    "\n",
    "with open (\"all_output.fas\",\"w\") as obj:\n",
    "    obj.write(txt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2217992099559a26038b70e11f392c50e16e825ff225ac028cf0711693f69c89"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
